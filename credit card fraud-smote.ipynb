{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: https://www.kaggle.com/dalpozz/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "FILE_NAME = 'creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Label  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "full_data = pd.read_csv(FILE_NAME)\n",
    "\n",
    "#rename the 'Class' column\n",
    "full_data.rename(columns = {'Class': 'Label'}, inplace = True)\n",
    "\n",
    "#let's take a peek\n",
    "print full_data.shape\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data consists of 284807 instances of data with 29 total features with value counts of \n",
      "0    284315\n",
      "1       492\n",
      "Name: Label, dtype: int64\n",
      "Where 0 indicates a legitimate transaction and 1 indicates fraud\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "full_data = shuffle(full_data)\n",
    "\n",
    "# Seperate target labels\n",
    "labels = full_data['Label']\n",
    "\n",
    "times = full_data['Time']\n",
    "features = full_data.drop(['Time', 'Label'], axis=1)\n",
    "\n",
    "# Get some specifics on our dataset\n",
    "print \"Data consists of {} instances of data with {} total features with value counts of \\n{}\".format(\n",
    "    features.shape[0], features.shape[1], labels.value_counts())\n",
    "print \"Where 0 indicates a legitimate transaction and 1 indicates fraud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the amount spent\n",
    "features['normAmount'] = StandardScaler().fit_transform(features['Amount'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42914</th>\n",
       "      <td>1.328755</td>\n",
       "      <td>-0.667281</td>\n",
       "      <td>0.143056</td>\n",
       "      <td>-0.525633</td>\n",
       "      <td>-1.193573</td>\n",
       "      <td>-1.171937</td>\n",
       "      <td>-0.389395</td>\n",
       "      <td>-0.194001</td>\n",
       "      <td>-0.661954</td>\n",
       "      <td>0.734371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515663</td>\n",
       "      <td>-0.384769</td>\n",
       "      <td>-0.798811</td>\n",
       "      <td>0.033199</td>\n",
       "      <td>0.379640</td>\n",
       "      <td>0.198983</td>\n",
       "      <td>1.042043</td>\n",
       "      <td>-0.085049</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>-0.165319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64702</th>\n",
       "      <td>-2.073365</td>\n",
       "      <td>1.212988</td>\n",
       "      <td>-0.210357</td>\n",
       "      <td>-3.817156</td>\n",
       "      <td>-0.342807</td>\n",
       "      <td>-1.086642</td>\n",
       "      <td>-0.385260</td>\n",
       "      <td>-0.907403</td>\n",
       "      <td>1.565272</td>\n",
       "      <td>-2.545380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710325</td>\n",
       "      <td>1.419176</td>\n",
       "      <td>-0.815893</td>\n",
       "      <td>-0.130419</td>\n",
       "      <td>-0.460201</td>\n",
       "      <td>0.480698</td>\n",
       "      <td>-1.173772</td>\n",
       "      <td>0.126028</td>\n",
       "      <td>-0.014738</td>\n",
       "      <td>-0.329041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23423</th>\n",
       "      <td>-8.913464</td>\n",
       "      <td>-7.608227</td>\n",
       "      <td>1.337346</td>\n",
       "      <td>-0.145191</td>\n",
       "      <td>1.546935</td>\n",
       "      <td>-0.219715</td>\n",
       "      <td>3.960317</td>\n",
       "      <td>-3.785540</td>\n",
       "      <td>3.959629</td>\n",
       "      <td>3.356782</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.157627</td>\n",
       "      <td>-2.924978</td>\n",
       "      <td>1.494810</td>\n",
       "      <td>2.426169</td>\n",
       "      <td>0.311150</td>\n",
       "      <td>1.370135</td>\n",
       "      <td>0.838952</td>\n",
       "      <td>-2.138323</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>1.026110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113824</th>\n",
       "      <td>1.290819</td>\n",
       "      <td>0.086102</td>\n",
       "      <td>-1.302560</td>\n",
       "      <td>-0.056117</td>\n",
       "      <td>2.253052</td>\n",
       "      <td>3.293045</td>\n",
       "      <td>-0.354302</td>\n",
       "      <td>0.763154</td>\n",
       "      <td>-0.153879</td>\n",
       "      <td>0.072484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009015</td>\n",
       "      <td>-0.022624</td>\n",
       "      <td>-0.178238</td>\n",
       "      <td>-0.139225</td>\n",
       "      <td>1.004248</td>\n",
       "      <td>0.846114</td>\n",
       "      <td>-0.313342</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>-0.317247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109444</th>\n",
       "      <td>-0.358580</td>\n",
       "      <td>0.966068</td>\n",
       "      <td>1.145574</td>\n",
       "      <td>-0.118194</td>\n",
       "      <td>0.114540</td>\n",
       "      <td>-0.506351</td>\n",
       "      <td>0.493812</td>\n",
       "      <td>0.182737</td>\n",
       "      <td>-0.399004</td>\n",
       "      <td>-0.295956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033848</td>\n",
       "      <td>-0.252584</td>\n",
       "      <td>-0.763710</td>\n",
       "      <td>-0.053691</td>\n",
       "      <td>-0.095451</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>0.080296</td>\n",
       "      <td>0.231897</td>\n",
       "      <td>0.081307</td>\n",
       "      <td>-0.346073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "42914   1.328755 -0.667281  0.143056 -0.525633 -1.193573 -1.171937 -0.389395   \n",
       "64702  -2.073365  1.212988 -0.210357 -3.817156 -0.342807 -1.086642 -0.385260   \n",
       "23423  -8.913464 -7.608227  1.337346 -0.145191  1.546935 -0.219715  3.960317   \n",
       "113824  1.290819  0.086102 -1.302560 -0.056117  2.253052  3.293045 -0.354302   \n",
       "109444 -0.358580  0.966068  1.145574 -0.118194  0.114540 -0.506351  0.493812   \n",
       "\n",
       "              V8        V9       V10     ...           V20       V21  \\\n",
       "42914  -0.194001 -0.661954  0.734371     ...     -0.515663 -0.384769   \n",
       "64702  -0.907403  1.565272 -2.545380     ...     -0.710325  1.419176   \n",
       "23423  -3.785540  3.959629  3.356782     ...     -7.157627 -2.924978   \n",
       "113824  0.763154 -0.153879  0.072484     ...     -0.009015 -0.022624   \n",
       "109444  0.182737 -0.399004 -0.295956     ...      0.033848 -0.252584   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "42914  -0.798811  0.033199  0.379640  0.198983  1.042043 -0.085049  0.007608   \n",
       "64702  -0.815893 -0.130419 -0.460201  0.480698 -1.173772  0.126028 -0.014738   \n",
       "23423   1.494810  2.426169  0.311150  1.370135  0.838952 -2.138323  0.008645   \n",
       "113824 -0.178238 -0.139225  1.004248  0.846114 -0.313342  0.015407  0.014375   \n",
       "109444 -0.763710 -0.053691 -0.095451 -0.198796  0.080296  0.231897  0.081307   \n",
       "\n",
       "        normAmount  \n",
       "42914    -0.165319  \n",
       "64702    -0.329041  \n",
       "23423     1.026110  \n",
       "113824   -0.317247  \n",
       "109444   -0.346073  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amounts = features['Amount']\n",
    "features = features.drop(['Amount'], axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#?????????????????\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# implement synthetic minority oversampling technique for a more balanced dataset to feed our model\n",
    "oversampler = SMOTE(random_state=331)\n",
    "os_features, os_labels = oversampler.fit_sample(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training instances of data: 398041\n",
      "training instances of fraud 199140\n",
      "testing instances of data: 170589\n",
      "testing instances of fraud: 85175\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(os_features, os_labels, test_size = .3)\n",
    "\n",
    "# Let's get an idea of what our new oversampled data looks like\n",
    "\n",
    "print 'training instances of data:' , len(y_train) \n",
    "print 'training instances of fraud' , np.count_nonzero(y_train)\n",
    "print 'testing instances of data:' , len(y_test) \n",
    "print 'testing instances of fraud:' , np.count_nonzero(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest Classifier:\n",
      "[ 0.99984698  0.99977312  0.99988392] 0.999834673774\n",
      "For K-Nearest Neighbors Classifier:\n",
      "[ 0.99902831  0.99874278  0.998986  ] 0.998919028957\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "print \"For Random Forest Classifier:\"\n",
    "rfscores = cross_val_score(rf, os_features, os_labels, scoring = f1_scorer)\n",
    "print rfscores, rfscores.mean()\n",
    "\n",
    "print \"For K-Nearest Neighbors Classifier:\"\n",
    "knnscores = cross_val_score(knn, os_features, os_labels, scoring = f1_scorer)\n",
    "print knnscores, knnscores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for simple majority vote is  0.999135510488\n"
     ]
    }
   ],
   "source": [
    "#majority vote benchmark without oversampling\n",
    "majority_vote_predictions = np.zeros(features.shape[0])\n",
    "print \"f1 score for simple majority vote is \" , f1_score(labels, majority_vote_predictions, pos_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] n_estimators=10, min_samples_split=6, criterion=entropy, max_features=21 \n",
      "[CV]  n_estimators=10, min_samples_split=6, criterion=entropy, max_features=21, score=0.999847 -   2.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, criterion=entropy, max_features=21 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, min_samples_split=6, criterion=entropy, max_features=21, score=0.999784 -   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=6, criterion=entropy, max_features=21 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, min_samples_split=6, criterion=entropy, max_features=21, score=0.999810 -   0.2s\n",
      "[CV] n_estimators=25, min_samples_split=2, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=25, min_samples_split=2, criterion=entropy, max_features=13, score=0.999847 -   0.6s\n",
      "[CV] n_estimators=25, min_samples_split=2, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=25, min_samples_split=2, criterion=entropy, max_features=13, score=0.999836 -   0.6s\n",
      "[CV] n_estimators=25, min_samples_split=2, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=25, min_samples_split=2, criterion=entropy, max_features=13, score=0.999858 -   0.6s\n",
      "[CV] n_estimators=100, min_samples_split=4, criterion=gini, max_features=25 \n",
      "[CV]  n_estimators=100, min_samples_split=4, criterion=gini, max_features=25, score=0.999583 -   4.2s\n",
      "[CV] n_estimators=100, min_samples_split=4, criterion=gini, max_features=25 \n",
      "[CV]  n_estimators=100, min_samples_split=4, criterion=gini, max_features=25, score=0.999594 -   2.9s\n",
      "[CV] n_estimators=100, min_samples_split=4, criterion=gini, max_features=25 \n",
      "[CV]  n_estimators=100, min_samples_split=4, criterion=gini, max_features=25, score=0.999657 -   3.0s\n",
      "[CV] n_estimators=85, min_samples_split=6, criterion=entropy, max_features=17 \n",
      "[CV]  n_estimators=85, min_samples_split=6, criterion=entropy, max_features=17, score=0.999858 -   2.4s\n",
      "[CV] n_estimators=85, min_samples_split=6, criterion=entropy, max_features=17 \n",
      "[CV]  n_estimators=85, min_samples_split=6, criterion=entropy, max_features=17, score=0.999847 -   2.1s\n",
      "[CV] n_estimators=85, min_samples_split=6, criterion=entropy, max_features=17 \n",
      "[CV]  n_estimators=85, min_samples_split=6, criterion=entropy, max_features=17, score=0.999863 -   2.0s\n",
      "[CV] n_estimators=100, min_samples_split=2, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=100, min_samples_split=2, criterion=gini, max_features=5, score=0.999884 -   3.0s\n",
      "[CV] n_estimators=100, min_samples_split=2, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=100, min_samples_split=2, criterion=gini, max_features=5, score=0.999831 -   3.1s\n",
      "[CV] n_estimators=100, min_samples_split=2, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=100, min_samples_split=2, criterion=gini, max_features=5, score=0.999884 -   3.1s\n",
      "[CV] n_estimators=40, min_samples_split=6, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=40, min_samples_split=6, criterion=gini, max_features=5, score=0.999868 -   1.1s\n",
      "[CV] n_estimators=40, min_samples_split=6, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=40, min_samples_split=6, criterion=gini, max_features=5, score=0.999847 -   1.2s\n",
      "[CV] n_estimators=40, min_samples_split=6, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=40, min_samples_split=6, criterion=gini, max_features=5, score=0.999873 -   1.4s\n",
      "[CV] n_estimators=55, min_samples_split=4, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=55, min_samples_split=4, criterion=entropy, max_features=13, score=0.999852 -   1.3s\n",
      "[CV] n_estimators=55, min_samples_split=4, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=55, min_samples_split=4, criterion=entropy, max_features=13, score=0.999858 -   1.3s\n",
      "[CV] n_estimators=55, min_samples_split=4, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=55, min_samples_split=4, criterion=entropy, max_features=13, score=0.999863 -   1.3s\n",
      "[CV] n_estimators=100, min_samples_split=4, criterion=gini, max_features=21 \n",
      "[CV]  n_estimators=100, min_samples_split=4, criterion=gini, max_features=21, score=0.999784 -   6.5s\n",
      "[CV] n_estimators=100, min_samples_split=4, criterion=gini, max_features=21 \n",
      "[CV]  n_estimators=100, min_samples_split=4, criterion=gini, max_features=21, score=0.999726 -   2.9s\n",
      "[CV] n_estimators=100, min_samples_split=4, criterion=gini, max_features=21 \n",
      "[CV]  n_estimators=100, min_samples_split=4, criterion=gini, max_features=21, score=0.999763 -   5.6s\n",
      "[CV] n_estimators=40, min_samples_split=2, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=40, min_samples_split=2, criterion=gini, max_features=1, score=0.999873 -   1.7s\n",
      "[CV] n_estimators=40, min_samples_split=2, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=40, min_samples_split=2, criterion=gini, max_features=1, score=0.999858 -   1.6s\n",
      "[CV] n_estimators=40, min_samples_split=2, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=40, min_samples_split=2, criterion=gini, max_features=1, score=0.999900 -   1.7s\n",
      "[CV] n_estimators=100, min_samples_split=6, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=100, min_samples_split=6, criterion=gini, max_features=5, score=0.999884 -  24.9s\n",
      "[CV] n_estimators=100, min_samples_split=6, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=100, min_samples_split=6, criterion=gini, max_features=5, score=0.999826 -   3.3s\n",
      "[CV] n_estimators=100, min_samples_split=6, criterion=gini, max_features=5 \n",
      "[CV]  n_estimators=100, min_samples_split=6, criterion=gini, max_features=5, score=0.999894 -   3.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=10, min_samples_split=4, criterion=gini, max_features=1, score=0.999831 -   0.7s\n",
      "[CV] n_estimators=10, min_samples_split=4, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=10, min_samples_split=4, criterion=gini, max_features=1, score=0.999715 -   0.3s\n",
      "[CV] n_estimators=10, min_samples_split=4, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=10, min_samples_split=4, criterion=gini, max_features=1, score=0.999800 -   0.3s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=gini, max_features=21 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=gini, max_features=21, score=0.999768 -   2.3s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=gini, max_features=21 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=gini, max_features=21, score=0.999705 -   2.0s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=gini, max_features=21 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=gini, max_features=21, score=0.999757 -   2.0s\n",
      "[CV] n_estimators=85, min_samples_split=2, criterion=entropy, max_features=1 \n",
      "[CV]  n_estimators=85, min_samples_split=2, criterion=entropy, max_features=1, score=0.999879 -   2.7s\n",
      "[CV] n_estimators=85, min_samples_split=2, criterion=entropy, max_features=1 \n",
      "[CV]  n_estimators=85, min_samples_split=2, criterion=entropy, max_features=1, score=0.999836 -   2.7s\n",
      "[CV] n_estimators=85, min_samples_split=2, criterion=entropy, max_features=1 \n",
      "[CV]  n_estimators=85, min_samples_split=2, criterion=entropy, max_features=1, score=0.999873 -   2.7s\n",
      "[CV] n_estimators=55, min_samples_split=2, criterion=gini, max_features=9 \n",
      "[CV]  n_estimators=55, min_samples_split=2, criterion=gini, max_features=9, score=0.999873 -   1.5s\n",
      "[CV] n_estimators=55, min_samples_split=2, criterion=gini, max_features=9 \n",
      "[CV]  n_estimators=55, min_samples_split=2, criterion=gini, max_features=9, score=0.999842 -   1.6s\n",
      "[CV] n_estimators=55, min_samples_split=2, criterion=gini, max_features=9 \n",
      "[CV]  n_estimators=55, min_samples_split=2, criterion=gini, max_features=9, score=0.999868 -   1.6s\n",
      "[CV] n_estimators=40, min_samples_split=2, criterion=gini, max_features=13 \n",
      "[CV]  n_estimators=40, min_samples_split=2, criterion=gini, max_features=13, score=0.999826 -  21.8s\n",
      "[CV] n_estimators=40, min_samples_split=2, criterion=gini, max_features=13 \n",
      "[CV]  n_estimators=40, min_samples_split=2, criterion=gini, max_features=13, score=0.999831 -   1.1s\n",
      "[CV] n_estimators=40, min_samples_split=2, criterion=gini, max_features=13 \n",
      "[CV]  n_estimators=40, min_samples_split=2, criterion=gini, max_features=13, score=0.999858 -   1.1s\n",
      "[CV] n_estimators=40, min_samples_split=6, criterion=entropy, max_features=9 \n",
      "[CV]  n_estimators=40, min_samples_split=6, criterion=entropy, max_features=9, score=0.999868 -   0.9s\n",
      "[CV] n_estimators=40, min_samples_split=6, criterion=entropy, max_features=9 \n",
      "[CV]  n_estimators=40, min_samples_split=6, criterion=entropy, max_features=9, score=0.999831 -   1.0s\n",
      "[CV] n_estimators=40, min_samples_split=6, criterion=entropy, max_features=9 \n",
      "[CV]  n_estimators=40, min_samples_split=6, criterion=entropy, max_features=9, score=0.999889 -   0.9s\n",
      "[CV] n_estimators=100, min_samples_split=2, criterion=entropy, max_features=25 \n",
      "[CV]  n_estimators=100, min_samples_split=2, criterion=entropy, max_features=25, score=0.999826 -   2.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, criterion=entropy, max_features=25 \n",
      "[CV]  n_estimators=100, min_samples_split=2, criterion=entropy, max_features=25, score=0.999815 -   3.7s\n",
      "[CV] n_estimators=100, min_samples_split=2, criterion=entropy, max_features=25 \n",
      "[CV]  n_estimators=100, min_samples_split=2, criterion=entropy, max_features=25, score=0.999784 -   2.3s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=entropy, max_features=21 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=entropy, max_features=21, score=0.999842 -   1.6s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=entropy, max_features=21 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=entropy, max_features=21, score=0.999852 -   1.7s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=entropy, max_features=21 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=entropy, max_features=21, score=0.999836 -   1.6s\n",
      "[CV] n_estimators=85, min_samples_split=4, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=85, min_samples_split=4, criterion=gini, max_features=1, score=0.999889 -   3.0s\n",
      "[CV] n_estimators=85, min_samples_split=4, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=85, min_samples_split=4, criterion=gini, max_features=1, score=0.999858 -   3.3s\n",
      "[CV] n_estimators=85, min_samples_split=4, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=85, min_samples_split=4, criterion=gini, max_features=1, score=0.999873 -   2.8s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=entropy, max_features=13, score=0.999858 -   1.7s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=entropy, max_features=13, score=0.999847 -   1.7s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=entropy, max_features=13 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=entropy, max_features=13, score=0.999852 -   1.8s\n",
      "[CV] n_estimators=85, min_samples_split=6, criterion=gini, max_features=25 \n",
      "[CV]  n_estimators=85, min_samples_split=6, criterion=gini, max_features=25, score=0.999573 -   2.5s\n",
      "[CV] n_estimators=85, min_samples_split=6, criterion=gini, max_features=25 \n",
      "[CV]  n_estimators=85, min_samples_split=6, criterion=gini, max_features=25, score=0.999631 -   2.5s\n",
      "[CV] n_estimators=85, min_samples_split=6, criterion=gini, max_features=25 \n",
      "[CV]  n_estimators=85, min_samples_split=6, criterion=gini, max_features=25, score=0.999662 -   2.7s\n",
      "[CV] n_estimators=70, min_samples_split=2, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=70, min_samples_split=2, criterion=gini, max_features=1, score=0.999894 -   2.4s\n",
      "[CV] n_estimators=70, min_samples_split=2, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=70, min_samples_split=2, criterion=gini, max_features=1, score=0.999863 -   2.6s\n",
      "[CV] n_estimators=70, min_samples_split=2, criterion=gini, max_features=1 \n",
      "[CV]  n_estimators=70, min_samples_split=2, criterion=gini, max_features=1, score=0.999879 -   2.4s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=gini, max_features=9 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=gini, max_features=9, score=0.999879 -   2.0s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=gini, max_features=9 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=gini, max_features=9, score=0.999847 -   2.2s\n",
      "[CV] n_estimators=70, min_samples_split=6, criterion=gini, max_features=9 \n",
      "[CV]  n_estimators=70, min_samples_split=6, criterion=gini, max_features=9, score=0.999852 -   2.7s\n",
      "[CV] n_estimators=55, min_samples_split=2, criterion=gini, max_features=17 \n",
      "[CV]  n_estimators=55, min_samples_split=2, criterion=gini, max_features=17, score=0.999831 -   1.6s\n",
      "[CV] n_estimators=55, min_samples_split=2, criterion=gini, max_features=17 \n",
      "[CV]  n_estimators=55, min_samples_split=2, criterion=gini, max_features=17, score=0.999799 -  11.9s\n",
      "[CV] n_estimators=55, min_samples_split=2, criterion=gini, max_features=17 \n",
      "[CV]  n_estimators=55, min_samples_split=2, criterion=gini, max_features=17, score=0.999815 -   1.6s\n",
      "[CV] n_estimators=100, min_samples_split=6, criterion=gini, max_features=13 \n",
      "[CV]  n_estimators=100, min_samples_split=6, criterion=gini, max_features=13, score=0.999873 -   2.9s\n",
      "[CV] n_estimators=100, min_samples_split=6, criterion=gini, max_features=13 \n",
      "[CV]  n_estimators=100, min_samples_split=6, criterion=gini, max_features=13, score=0.999831 -   3.1s\n",
      "[CV] n_estimators=100, min_samples_split=6, criterion=gini, max_features=13 \n",
      "[CV]  n_estimators=100, min_samples_split=6, criterion=gini, max_features=13, score=0.999847 -   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 908.1min finished\n"
     ]
    }
   ],
   "source": [
    "rf_params = {'n_estimators' : np.arange(10, 110, 15),\n",
    "                'min_samples_split': np.arange(2, 8, 2),\n",
    "                'max_features': np.arange(1, 29, 4),\n",
    "                'criterion': ['gini', 'entropy']}\n",
    "\n",
    "\n",
    "rf_tune = RandomizedSearchCV(rf, rf_params, n_iter = 25, scoring = f1_scorer, verbose = 3)\n",
    "\n",
    "rf_tune = rf_tune.fit(os_features, os_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=70, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False) \n",
      "f1 score: 0.999878640823\n"
     ]
    }
   ],
   "source": [
    "print rf_tune.best_estimator_ , '\\nf1 score:' , rf_tune.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunny\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Sunny\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.77979815,  -2.4083033 ,  -6.78178904, ..., -11.51279393,\n",
       "         -2.64945294,  -3.14909065],\n",
       "       [  4.64240508,  -4.99037778,  -5.86794173, ...,  -7.66904746,\n",
       "         -7.7372006 , -13.11827082],\n",
       "       [  1.08121135,  -1.18875625,   0.43640721, ...,   2.49536783,\n",
       "          0.5319671 ,   0.96720549],\n",
       "       ..., \n",
       "       [  4.33728493,  -3.8956539 ,  -4.93466896, ...,  -6.65599087,\n",
       "         -3.77057018,  -3.96300091],\n",
       "       [  5.17480293,  -4.51445392,  -0.27586251, ...,  -7.94539257,\n",
       "         -1.69056425,  -3.27894219],\n",
       "       [ -1.22037931,  -0.76978865,   1.29833454, ...,  -0.6222773 ,\n",
       "         -0.23289928,   0.35035864]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rft = rf_tune.best_estimator_\n",
    "rft.fit_transform(X_train, y_train)\n",
    "\n",
    "rfu = RandomForestClassifier()\n",
    "rfu.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 testing score for tuned random forest is  0.999900474794\n",
      "f1 testing score for random forest is  0.999777551427\n"
     ]
    }
   ],
   "source": [
    "# Check performances of tuned and untuned models\n",
    "print \"f1 testing score for tuned random forest is \", f1_score(y_test, rft.predict(X_test), pos_label = 0)\n",
    "\n",
    "print \"f1 testing score for random forest is \" , f1_score(y_test, rfu.predict(X_test), pos_label = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oops, looks like I could have chosen a better selection of hyper parameters for the randomized search cross validation optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85397,    17],\n",
       "       [    0, 85175]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, rft.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now let's try a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's build a model\n",
    "\n",
    "#add regularization\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = X_train.shape[1], activation = 'tanh', init = 'lecun_uniform'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(20, activation = 'tanh', init = 'lecun_uniform'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(8, activation = 'tanh', init = 'lecun_uniform'))\n",
    "model.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "sgd = SGD(lr = .1, momentum = .8, decay = .001)\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['fmeasure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 318432 samples, validate on 79609 samples\n",
      "Epoch 1/400\n",
      "5s - loss: 0.1614 - fmeasure: 0.9385 - val_loss: 0.1023 - val_fmeasure: 0.9587\n",
      "Epoch 2/400\n",
      "2s - loss: 0.1130 - fmeasure: 0.9550 - val_loss: 0.0874 - val_fmeasure: 0.9638\n",
      "Epoch 3/400\n",
      "3s - loss: 0.1023 - fmeasure: 0.9590 - val_loss: 0.0788 - val_fmeasure: 0.9691\n",
      "Epoch 4/400\n",
      "3s - loss: 0.0961 - fmeasure: 0.9613 - val_loss: 0.0728 - val_fmeasure: 0.9716\n",
      "Epoch 5/400\n",
      "3s - loss: 0.0904 - fmeasure: 0.9635 - val_loss: 0.0684 - val_fmeasure: 0.9729\n",
      "Epoch 6/400\n",
      "3s - loss: 0.0872 - fmeasure: 0.9646 - val_loss: 0.0646 - val_fmeasure: 0.9743\n",
      "Epoch 7/400\n",
      "3s - loss: 0.0834 - fmeasure: 0.9662 - val_loss: 0.0614 - val_fmeasure: 0.9757\n",
      "Epoch 8/400\n",
      "3s - loss: 0.0799 - fmeasure: 0.9674 - val_loss: 0.0586 - val_fmeasure: 0.9761\n",
      "Epoch 9/400\n",
      "3s - loss: 0.0774 - fmeasure: 0.9684 - val_loss: 0.0564 - val_fmeasure: 0.9772\n",
      "Epoch 10/400\n",
      "3s - loss: 0.0760 - fmeasure: 0.9690 - val_loss: 0.0541 - val_fmeasure: 0.9781\n",
      "Epoch 11/400\n",
      "3s - loss: 0.0737 - fmeasure: 0.9699 - val_loss: 0.0521 - val_fmeasure: 0.9786\n",
      "Epoch 12/400\n",
      "3s - loss: 0.0719 - fmeasure: 0.9704 - val_loss: 0.0508 - val_fmeasure: 0.9796\n",
      "Epoch 13/400\n",
      "3s - loss: 0.0701 - fmeasure: 0.9717 - val_loss: 0.0490 - val_fmeasure: 0.9804\n",
      "Epoch 14/400\n",
      "2s - loss: 0.0689 - fmeasure: 0.9719 - val_loss: 0.0481 - val_fmeasure: 0.9812\n",
      "Epoch 15/400\n",
      "3s - loss: 0.0676 - fmeasure: 0.9724 - val_loss: 0.0465 - val_fmeasure: 0.9817\n",
      "Epoch 16/400\n",
      "3s - loss: 0.0665 - fmeasure: 0.9731 - val_loss: 0.0461 - val_fmeasure: 0.9821\n",
      "Epoch 17/400\n",
      "3s - loss: 0.0657 - fmeasure: 0.9732 - val_loss: 0.0447 - val_fmeasure: 0.9824\n",
      "Epoch 18/400\n",
      "3s - loss: 0.0648 - fmeasure: 0.9735 - val_loss: 0.0435 - val_fmeasure: 0.9829\n",
      "Epoch 19/400\n",
      "3s - loss: 0.0638 - fmeasure: 0.9740 - val_loss: 0.0432 - val_fmeasure: 0.9831\n",
      "Epoch 20/400\n",
      "3s - loss: 0.0630 - fmeasure: 0.9743 - val_loss: 0.0422 - val_fmeasure: 0.9835\n",
      "Epoch 21/400\n",
      "3s - loss: 0.0626 - fmeasure: 0.9747 - val_loss: 0.0415 - val_fmeasure: 0.9840\n",
      "Epoch 22/400\n",
      "3s - loss: 0.0614 - fmeasure: 0.9754 - val_loss: 0.0408 - val_fmeasure: 0.9842\n",
      "Epoch 23/400\n",
      "3s - loss: 0.0608 - fmeasure: 0.9755 - val_loss: 0.0399 - val_fmeasure: 0.9846\n",
      "Epoch 24/400\n",
      "2s - loss: 0.0601 - fmeasure: 0.9757 - val_loss: 0.0396 - val_fmeasure: 0.9848\n",
      "Epoch 25/400\n",
      "3s - loss: 0.0599 - fmeasure: 0.9756 - val_loss: 0.0390 - val_fmeasure: 0.9851\n",
      "Epoch 26/400\n",
      "3s - loss: 0.0588 - fmeasure: 0.9767 - val_loss: 0.0387 - val_fmeasure: 0.9851\n",
      "Epoch 27/400\n",
      "2s - loss: 0.0590 - fmeasure: 0.9761 - val_loss: 0.0380 - val_fmeasure: 0.9855\n",
      "Epoch 28/400\n",
      "3s - loss: 0.0580 - fmeasure: 0.9765 - val_loss: 0.0375 - val_fmeasure: 0.9855\n",
      "Epoch 29/400\n",
      "3s - loss: 0.0574 - fmeasure: 0.9769 - val_loss: 0.0370 - val_fmeasure: 0.9857\n",
      "Epoch 30/400\n",
      "3s - loss: 0.0573 - fmeasure: 0.9770 - val_loss: 0.0365 - val_fmeasure: 0.9859\n",
      "Epoch 31/400\n",
      "3s - loss: 0.0566 - fmeasure: 0.9774 - val_loss: 0.0362 - val_fmeasure: 0.9861\n",
      "Epoch 32/400\n",
      "3s - loss: 0.0562 - fmeasure: 0.9777 - val_loss: 0.0356 - val_fmeasure: 0.9862\n",
      "Epoch 33/400\n",
      "3s - loss: 0.0560 - fmeasure: 0.9778 - val_loss: 0.0354 - val_fmeasure: 0.9864\n",
      "Epoch 34/400\n",
      "3s - loss: 0.0555 - fmeasure: 0.9778 - val_loss: 0.0351 - val_fmeasure: 0.9864\n",
      "Epoch 35/400\n",
      "3s - loss: 0.0553 - fmeasure: 0.9776 - val_loss: 0.0347 - val_fmeasure: 0.9866\n",
      "Epoch 36/400\n",
      "3s - loss: 0.0543 - fmeasure: 0.9783 - val_loss: 0.0347 - val_fmeasure: 0.9866\n",
      "Epoch 37/400\n",
      "3s - loss: 0.0543 - fmeasure: 0.9783 - val_loss: 0.0343 - val_fmeasure: 0.9868\n",
      "Epoch 38/400\n",
      "3s - loss: 0.0542 - fmeasure: 0.9784 - val_loss: 0.0338 - val_fmeasure: 0.9869\n",
      "Epoch 39/400\n",
      "3s - loss: 0.0541 - fmeasure: 0.9785 - val_loss: 0.0338 - val_fmeasure: 0.9870\n",
      "Epoch 40/400\n",
      "3s - loss: 0.0537 - fmeasure: 0.9786 - val_loss: 0.0336 - val_fmeasure: 0.9870\n",
      "Epoch 41/400\n",
      "3s - loss: 0.0536 - fmeasure: 0.9786 - val_loss: 0.0332 - val_fmeasure: 0.9871\n",
      "Epoch 42/400\n",
      "3s - loss: 0.0531 - fmeasure: 0.9787 - val_loss: 0.0327 - val_fmeasure: 0.9872\n",
      "Epoch 43/400\n",
      "3s - loss: 0.0531 - fmeasure: 0.9790 - val_loss: 0.0327 - val_fmeasure: 0.9875\n",
      "Epoch 44/400\n",
      "3s - loss: 0.0528 - fmeasure: 0.9791 - val_loss: 0.0325 - val_fmeasure: 0.9876\n",
      "Epoch 45/400\n",
      "2s - loss: 0.0521 - fmeasure: 0.9792 - val_loss: 0.0320 - val_fmeasure: 0.9878\n",
      "Epoch 46/400\n",
      "2s - loss: 0.0517 - fmeasure: 0.9796 - val_loss: 0.0320 - val_fmeasure: 0.9878\n",
      "Epoch 47/400\n",
      "2s - loss: 0.0519 - fmeasure: 0.9793 - val_loss: 0.0317 - val_fmeasure: 0.9882\n",
      "Epoch 48/400\n",
      "3s - loss: 0.0519 - fmeasure: 0.9794 - val_loss: 0.0315 - val_fmeasure: 0.9883\n",
      "Epoch 49/400\n",
      "3s - loss: 0.0515 - fmeasure: 0.9798 - val_loss: 0.0315 - val_fmeasure: 0.9883\n",
      "Epoch 50/400\n",
      "3s - loss: 0.0509 - fmeasure: 0.9797 - val_loss: 0.0314 - val_fmeasure: 0.9883\n",
      "Epoch 51/400\n",
      "4s - loss: 0.0508 - fmeasure: 0.9802 - val_loss: 0.0311 - val_fmeasure: 0.9886\n",
      "Epoch 52/400\n",
      "3s - loss: 0.0503 - fmeasure: 0.9798 - val_loss: 0.0309 - val_fmeasure: 0.9886\n",
      "Epoch 53/400\n",
      "3s - loss: 0.0501 - fmeasure: 0.9803 - val_loss: 0.0307 - val_fmeasure: 0.9886\n",
      "Epoch 54/400\n",
      "3s - loss: 0.0503 - fmeasure: 0.9802 - val_loss: 0.0306 - val_fmeasure: 0.9887\n",
      "Epoch 55/400\n",
      "3s - loss: 0.0507 - fmeasure: 0.9799 - val_loss: 0.0305 - val_fmeasure: 0.9888\n",
      "Epoch 56/400\n",
      "3s - loss: 0.0499 - fmeasure: 0.9804 - val_loss: 0.0304 - val_fmeasure: 0.9889\n",
      "Epoch 57/400\n",
      "3s - loss: 0.0500 - fmeasure: 0.9805 - val_loss: 0.0301 - val_fmeasure: 0.9888\n",
      "Epoch 58/400\n",
      "3s - loss: 0.0501 - fmeasure: 0.9803 - val_loss: 0.0302 - val_fmeasure: 0.9889\n",
      "Epoch 59/400\n",
      "3s - loss: 0.0500 - fmeasure: 0.9803 - val_loss: 0.0301 - val_fmeasure: 0.9888\n",
      "Epoch 60/400\n",
      "3s - loss: 0.0489 - fmeasure: 0.9804 - val_loss: 0.0300 - val_fmeasure: 0.9890\n",
      "Epoch 61/400\n",
      "3s - loss: 0.0493 - fmeasure: 0.9805 - val_loss: 0.0298 - val_fmeasure: 0.9890\n",
      "Epoch 62/400\n",
      "3s - loss: 0.0492 - fmeasure: 0.9804 - val_loss: 0.0297 - val_fmeasure: 0.9890\n",
      "Epoch 63/400\n",
      "3s - loss: 0.0489 - fmeasure: 0.9807 - val_loss: 0.0297 - val_fmeasure: 0.9890\n",
      "Epoch 64/400\n",
      "3s - loss: 0.0486 - fmeasure: 0.9810 - val_loss: 0.0294 - val_fmeasure: 0.9891\n",
      "Epoch 65/400\n",
      "3s - loss: 0.0492 - fmeasure: 0.9807 - val_loss: 0.0293 - val_fmeasure: 0.9892\n",
      "Epoch 66/400\n",
      "3s - loss: 0.0483 - fmeasure: 0.9811 - val_loss: 0.0292 - val_fmeasure: 0.9892\n",
      "Epoch 67/400\n",
      "3s - loss: 0.0484 - fmeasure: 0.9808 - val_loss: 0.0289 - val_fmeasure: 0.9894\n",
      "Epoch 68/400\n",
      "3s - loss: 0.0481 - fmeasure: 0.9814 - val_loss: 0.0290 - val_fmeasure: 0.9892\n",
      "Epoch 69/400\n",
      "3s - loss: 0.0478 - fmeasure: 0.9811 - val_loss: 0.0287 - val_fmeasure: 0.9894\n",
      "Epoch 70/400\n",
      "3s - loss: 0.0481 - fmeasure: 0.9812 - val_loss: 0.0288 - val_fmeasure: 0.9893\n",
      "Epoch 71/400\n",
      "3s - loss: 0.0475 - fmeasure: 0.9815 - val_loss: 0.0286 - val_fmeasure: 0.9894\n",
      "Epoch 72/400\n",
      "3s - loss: 0.0476 - fmeasure: 0.9813 - val_loss: 0.0286 - val_fmeasure: 0.9894\n",
      "Epoch 73/400\n",
      "3s - loss: 0.0478 - fmeasure: 0.9812 - val_loss: 0.0284 - val_fmeasure: 0.9895\n",
      "Epoch 74/400\n",
      "4s - loss: 0.0480 - fmeasure: 0.9812 - val_loss: 0.0284 - val_fmeasure: 0.9895\n",
      "Epoch 75/400\n",
      "3s - loss: 0.0471 - fmeasure: 0.9816 - val_loss: 0.0282 - val_fmeasure: 0.9895\n",
      "Epoch 76/400\n",
      "3s - loss: 0.0472 - fmeasure: 0.9815 - val_loss: 0.0282 - val_fmeasure: 0.9896\n",
      "Epoch 77/400\n",
      "3s - loss: 0.0469 - fmeasure: 0.9818 - val_loss: 0.0281 - val_fmeasure: 0.9896\n",
      "Epoch 78/400\n",
      "3s - loss: 0.0473 - fmeasure: 0.9816 - val_loss: 0.0280 - val_fmeasure: 0.9896\n",
      "Epoch 79/400\n",
      "3s - loss: 0.0465 - fmeasure: 0.9819 - val_loss: 0.0278 - val_fmeasure: 0.9897\n",
      "Epoch 80/400\n",
      "4s - loss: 0.0464 - fmeasure: 0.9817 - val_loss: 0.0278 - val_fmeasure: 0.9897\n",
      "Epoch 81/400\n",
      "4s - loss: 0.0470 - fmeasure: 0.9817 - val_loss: 0.0279 - val_fmeasure: 0.9896\n",
      "Epoch 82/400\n",
      "3s - loss: 0.0468 - fmeasure: 0.9818 - val_loss: 0.0278 - val_fmeasure: 0.9897\n",
      "Epoch 83/400\n",
      "3s - loss: 0.0469 - fmeasure: 0.9817 - val_loss: 0.0276 - val_fmeasure: 0.9898\n",
      "Epoch 84/400\n",
      "3s - loss: 0.0465 - fmeasure: 0.9818 - val_loss: 0.0274 - val_fmeasure: 0.9899\n",
      "Epoch 85/400\n",
      "3s - loss: 0.0463 - fmeasure: 0.9819 - val_loss: 0.0271 - val_fmeasure: 0.9900\n",
      "Epoch 86/400\n",
      "3s - loss: 0.0458 - fmeasure: 0.9822 - val_loss: 0.0273 - val_fmeasure: 0.9899\n",
      "Epoch 87/400\n",
      "4s - loss: 0.0467 - fmeasure: 0.9815 - val_loss: 0.0272 - val_fmeasure: 0.9900\n",
      "Epoch 88/400\n",
      "4s - loss: 0.0460 - fmeasure: 0.9821 - val_loss: 0.0273 - val_fmeasure: 0.9899\n",
      "Epoch 89/400\n",
      "3s - loss: 0.0461 - fmeasure: 0.9820 - val_loss: 0.0271 - val_fmeasure: 0.9901\n",
      "Epoch 90/400\n",
      "3s - loss: 0.0455 - fmeasure: 0.9821 - val_loss: 0.0271 - val_fmeasure: 0.9901\n",
      "Epoch 91/400\n",
      "3s - loss: 0.0455 - fmeasure: 0.9823 - val_loss: 0.0269 - val_fmeasure: 0.9902\n",
      "Epoch 92/400\n",
      "3s - loss: 0.0450 - fmeasure: 0.9825 - val_loss: 0.0270 - val_fmeasure: 0.9901\n",
      "Epoch 93/400\n",
      "3s - loss: 0.0455 - fmeasure: 0.9821 - val_loss: 0.0267 - val_fmeasure: 0.9903\n",
      "Epoch 94/400\n",
      "3s - loss: 0.0452 - fmeasure: 0.9824 - val_loss: 0.0267 - val_fmeasure: 0.9903\n",
      "Epoch 95/400\n",
      "4s - loss: 0.0449 - fmeasure: 0.9825 - val_loss: 0.0267 - val_fmeasure: 0.9903\n",
      "Epoch 96/400\n",
      "3s - loss: 0.0452 - fmeasure: 0.9826 - val_loss: 0.0265 - val_fmeasure: 0.9904\n",
      "Epoch 97/400\n",
      "3s - loss: 0.0445 - fmeasure: 0.9827 - val_loss: 0.0265 - val_fmeasure: 0.9905\n",
      "Epoch 98/400\n",
      "4s - loss: 0.0451 - fmeasure: 0.9825 - val_loss: 0.0265 - val_fmeasure: 0.9904\n",
      "Epoch 99/400\n",
      "3s - loss: 0.0451 - fmeasure: 0.9824 - val_loss: 0.0264 - val_fmeasure: 0.9904\n",
      "Epoch 100/400\n",
      "3s - loss: 0.0448 - fmeasure: 0.9824 - val_loss: 0.0262 - val_fmeasure: 0.9905\n",
      "Epoch 101/400\n",
      "3s - loss: 0.0454 - fmeasure: 0.9823 - val_loss: 0.0265 - val_fmeasure: 0.9904\n",
      "Epoch 102/400\n",
      "3s - loss: 0.0445 - fmeasure: 0.9828 - val_loss: 0.0262 - val_fmeasure: 0.9905\n",
      "Epoch 103/400\n",
      "3s - loss: 0.0452 - fmeasure: 0.9824 - val_loss: 0.0262 - val_fmeasure: 0.9905\n",
      "Epoch 104/400\n",
      "3s - loss: 0.0444 - fmeasure: 0.9830 - val_loss: 0.0262 - val_fmeasure: 0.9905\n",
      "Epoch 105/400\n",
      "3s - loss: 0.0448 - fmeasure: 0.9827 - val_loss: 0.0262 - val_fmeasure: 0.9905\n",
      "Epoch 106/400\n",
      "4s - loss: 0.0445 - fmeasure: 0.9826 - val_loss: 0.0259 - val_fmeasure: 0.9906\n",
      "Epoch 107/400\n",
      "4s - loss: 0.0447 - fmeasure: 0.9826 - val_loss: 0.0260 - val_fmeasure: 0.9906\n",
      "Epoch 108/400\n",
      "4s - loss: 0.0446 - fmeasure: 0.9828 - val_loss: 0.0259 - val_fmeasure: 0.9906\n",
      "Epoch 109/400\n",
      "3s - loss: 0.0444 - fmeasure: 0.9827 - val_loss: 0.0259 - val_fmeasure: 0.9906\n",
      "Epoch 110/400\n",
      "4s - loss: 0.0443 - fmeasure: 0.9828 - val_loss: 0.0259 - val_fmeasure: 0.9906\n",
      "Epoch 111/400\n",
      "4s - loss: 0.0440 - fmeasure: 0.9829 - val_loss: 0.0258 - val_fmeasure: 0.9907\n",
      "Epoch 112/400\n",
      "4s - loss: 0.0435 - fmeasure: 0.9832 - val_loss: 0.0258 - val_fmeasure: 0.9906\n",
      "Epoch 113/400\n",
      "4s - loss: 0.0446 - fmeasure: 0.9827 - val_loss: 0.0260 - val_fmeasure: 0.9905\n",
      "Epoch 114/400\n",
      "3s - loss: 0.0439 - fmeasure: 0.9829 - val_loss: 0.0257 - val_fmeasure: 0.9907\n",
      "Epoch 115/400\n",
      "3s - loss: 0.0437 - fmeasure: 0.9829 - val_loss: 0.0257 - val_fmeasure: 0.9906\n",
      "Epoch 116/400\n",
      "3s - loss: 0.0441 - fmeasure: 0.9827 - val_loss: 0.0256 - val_fmeasure: 0.9906\n",
      "Epoch 117/400\n",
      "3s - loss: 0.0432 - fmeasure: 0.9834 - val_loss: 0.0254 - val_fmeasure: 0.9908\n",
      "Epoch 118/400\n",
      "3s - loss: 0.0439 - fmeasure: 0.9831 - val_loss: 0.0255 - val_fmeasure: 0.9907\n",
      "Epoch 119/400\n",
      "3s - loss: 0.0438 - fmeasure: 0.9831 - val_loss: 0.0256 - val_fmeasure: 0.9906\n",
      "Epoch 120/400\n",
      "3s - loss: 0.0437 - fmeasure: 0.9833 - val_loss: 0.0255 - val_fmeasure: 0.9907\n",
      "Epoch 121/400\n",
      "3s - loss: 0.0435 - fmeasure: 0.9832 - val_loss: 0.0254 - val_fmeasure: 0.9907\n",
      "Epoch 122/400\n",
      "3s - loss: 0.0433 - fmeasure: 0.9830 - val_loss: 0.0253 - val_fmeasure: 0.9908\n",
      "Epoch 123/400\n",
      "3s - loss: 0.0437 - fmeasure: 0.9831 - val_loss: 0.0254 - val_fmeasure: 0.9907\n",
      "Epoch 124/400\n",
      "3s - loss: 0.0431 - fmeasure: 0.9832 - val_loss: 0.0252 - val_fmeasure: 0.9908\n",
      "Epoch 125/400\n",
      "3s - loss: 0.0434 - fmeasure: 0.9831 - val_loss: 0.0252 - val_fmeasure: 0.9908\n",
      "Epoch 126/400\n",
      "3s - loss: 0.0433 - fmeasure: 0.9834 - val_loss: 0.0251 - val_fmeasure: 0.9908\n",
      "Epoch 127/400\n",
      "2s - loss: 0.0434 - fmeasure: 0.9834 - val_loss: 0.0251 - val_fmeasure: 0.9909\n",
      "Epoch 128/400\n",
      "3s - loss: 0.0435 - fmeasure: 0.9830 - val_loss: 0.0251 - val_fmeasure: 0.9908\n",
      "Epoch 129/400\n",
      "3s - loss: 0.0432 - fmeasure: 0.9835 - val_loss: 0.0251 - val_fmeasure: 0.9908\n",
      "Epoch 130/400\n",
      "3s - loss: 0.0431 - fmeasure: 0.9834 - val_loss: 0.0249 - val_fmeasure: 0.9909\n",
      "Epoch 131/400\n",
      "3s - loss: 0.0430 - fmeasure: 0.9836 - val_loss: 0.0250 - val_fmeasure: 0.9909\n",
      "Epoch 132/400\n",
      "3s - loss: 0.0433 - fmeasure: 0.9831 - val_loss: 0.0250 - val_fmeasure: 0.9909\n",
      "Epoch 133/400\n",
      "3s - loss: 0.0429 - fmeasure: 0.9834 - val_loss: 0.0249 - val_fmeasure: 0.9909\n",
      "Epoch 134/400\n",
      "3s - loss: 0.0430 - fmeasure: 0.9834 - val_loss: 0.0249 - val_fmeasure: 0.9909\n",
      "Epoch 135/400\n",
      "3s - loss: 0.0437 - fmeasure: 0.9828 - val_loss: 0.0249 - val_fmeasure: 0.9909\n",
      "Epoch 136/400\n",
      "3s - loss: 0.0427 - fmeasure: 0.9837 - val_loss: 0.0249 - val_fmeasure: 0.9910\n",
      "Epoch 137/400\n",
      "3s - loss: 0.0428 - fmeasure: 0.9832 - val_loss: 0.0248 - val_fmeasure: 0.9911\n",
      "Epoch 138/400\n",
      "3s - loss: 0.0427 - fmeasure: 0.9834 - val_loss: 0.0248 - val_fmeasure: 0.9911\n",
      "Epoch 139/400\n",
      "3s - loss: 0.0425 - fmeasure: 0.9838 - val_loss: 0.0246 - val_fmeasure: 0.9911\n",
      "Epoch 140/400\n",
      "3s - loss: 0.0426 - fmeasure: 0.9835 - val_loss: 0.0246 - val_fmeasure: 0.9911\n",
      "Epoch 141/400\n",
      "3s - loss: 0.0428 - fmeasure: 0.9835 - val_loss: 0.0247 - val_fmeasure: 0.9911\n",
      "Epoch 142/400\n",
      "3s - loss: 0.0426 - fmeasure: 0.9836 - val_loss: 0.0246 - val_fmeasure: 0.9911\n",
      "Epoch 143/400\n",
      "3s - loss: 0.0426 - fmeasure: 0.9836 - val_loss: 0.0246 - val_fmeasure: 0.9911\n",
      "Epoch 144/400\n",
      "3s - loss: 0.0426 - fmeasure: 0.9837 - val_loss: 0.0246 - val_fmeasure: 0.9911\n",
      "Epoch 145/400\n",
      "3s - loss: 0.0426 - fmeasure: 0.9833 - val_loss: 0.0246 - val_fmeasure: 0.9911\n",
      "Epoch 146/400\n",
      "3s - loss: 0.0424 - fmeasure: 0.9837 - val_loss: 0.0245 - val_fmeasure: 0.9912\n",
      "Epoch 147/400\n",
      "3s - loss: 0.0422 - fmeasure: 0.9838 - val_loss: 0.0246 - val_fmeasure: 0.9911\n",
      "Epoch 148/400\n",
      "3s - loss: 0.0421 - fmeasure: 0.9839 - val_loss: 0.0244 - val_fmeasure: 0.9911\n",
      "Epoch 149/400\n",
      "3s - loss: 0.0424 - fmeasure: 0.9835 - val_loss: 0.0243 - val_fmeasure: 0.9912\n",
      "Epoch 150/400\n",
      "3s - loss: 0.0427 - fmeasure: 0.9835 - val_loss: 0.0243 - val_fmeasure: 0.9912\n",
      "Epoch 151/400\n",
      "3s - loss: 0.0421 - fmeasure: 0.9841 - val_loss: 0.0244 - val_fmeasure: 0.9912\n",
      "Epoch 152/400\n",
      "3s - loss: 0.0423 - fmeasure: 0.9836 - val_loss: 0.0242 - val_fmeasure: 0.9912\n",
      "Epoch 153/400\n",
      "3s - loss: 0.0419 - fmeasure: 0.9838 - val_loss: 0.0243 - val_fmeasure: 0.9912\n",
      "Epoch 154/400\n",
      "3s - loss: 0.0422 - fmeasure: 0.9837 - val_loss: 0.0243 - val_fmeasure: 0.9912\n",
      "Epoch 155/400\n",
      "3s - loss: 0.0423 - fmeasure: 0.9838 - val_loss: 0.0241 - val_fmeasure: 0.9913\n",
      "Epoch 156/400\n",
      "3s - loss: 0.0422 - fmeasure: 0.9839 - val_loss: 0.0241 - val_fmeasure: 0.9913\n",
      "Epoch 157/400\n",
      "3s - loss: 0.0421 - fmeasure: 0.9840 - val_loss: 0.0241 - val_fmeasure: 0.9913\n",
      "Epoch 158/400\n",
      "3s - loss: 0.0414 - fmeasure: 0.9841 - val_loss: 0.0241 - val_fmeasure: 0.9913\n",
      "Epoch 159/400\n",
      "3s - loss: 0.0421 - fmeasure: 0.9837 - val_loss: 0.0240 - val_fmeasure: 0.9913\n",
      "Epoch 160/400\n",
      "3s - loss: 0.0417 - fmeasure: 0.9838 - val_loss: 0.0240 - val_fmeasure: 0.9914\n",
      "Epoch 161/400\n",
      "3s - loss: 0.0417 - fmeasure: 0.9841 - val_loss: 0.0240 - val_fmeasure: 0.9914\n",
      "Epoch 162/400\n",
      "3s - loss: 0.0417 - fmeasure: 0.9840 - val_loss: 0.0240 - val_fmeasure: 0.9914\n",
      "Epoch 163/400\n",
      "3s - loss: 0.0417 - fmeasure: 0.9839 - val_loss: 0.0239 - val_fmeasure: 0.9915\n",
      "Epoch 164/400\n",
      "3s - loss: 0.0415 - fmeasure: 0.9841 - val_loss: 0.0239 - val_fmeasure: 0.9915\n",
      "Epoch 165/400\n",
      "3s - loss: 0.0416 - fmeasure: 0.9839 - val_loss: 0.0240 - val_fmeasure: 0.9915\n",
      "Epoch 166/400\n",
      "3s - loss: 0.0419 - fmeasure: 0.9839 - val_loss: 0.0239 - val_fmeasure: 0.9915\n",
      "Epoch 167/400\n",
      "3s - loss: 0.0414 - fmeasure: 0.9843 - val_loss: 0.0239 - val_fmeasure: 0.9915\n",
      "Epoch 168/400\n",
      "3s - loss: 0.0421 - fmeasure: 0.9841 - val_loss: 0.0237 - val_fmeasure: 0.9915\n",
      "Epoch 169/400\n",
      "3s - loss: 0.0414 - fmeasure: 0.9840 - val_loss: 0.0238 - val_fmeasure: 0.9915\n",
      "Epoch 170/400\n",
      "3s - loss: 0.0418 - fmeasure: 0.9838 - val_loss: 0.0238 - val_fmeasure: 0.9914\n",
      "Epoch 171/400\n",
      "3s - loss: 0.0420 - fmeasure: 0.9839 - val_loss: 0.0238 - val_fmeasure: 0.9915\n",
      "Epoch 172/400\n",
      "3s - loss: 0.0413 - fmeasure: 0.9839 - val_loss: 0.0237 - val_fmeasure: 0.9916\n",
      "Epoch 173/400\n",
      "3s - loss: 0.0414 - fmeasure: 0.9841 - val_loss: 0.0237 - val_fmeasure: 0.9915\n",
      "Epoch 174/400\n",
      "3s - loss: 0.0415 - fmeasure: 0.9842 - val_loss: 0.0238 - val_fmeasure: 0.9915\n",
      "Epoch 175/400\n",
      "4s - loss: 0.0407 - fmeasure: 0.9843 - val_loss: 0.0236 - val_fmeasure: 0.9916\n",
      "Epoch 176/400\n",
      "3s - loss: 0.0414 - fmeasure: 0.9842 - val_loss: 0.0236 - val_fmeasure: 0.9915\n",
      "Epoch 177/400\n",
      "3s - loss: 0.0414 - fmeasure: 0.9842 - val_loss: 0.0237 - val_fmeasure: 0.9915\n",
      "Epoch 178/400\n",
      "3s - loss: 0.0412 - fmeasure: 0.9842 - val_loss: 0.0236 - val_fmeasure: 0.9915\n",
      "Epoch 179/400\n",
      "3s - loss: 0.0415 - fmeasure: 0.9840 - val_loss: 0.0235 - val_fmeasure: 0.9915\n",
      "Epoch 180/400\n",
      "3s - loss: 0.0415 - fmeasure: 0.9841 - val_loss: 0.0236 - val_fmeasure: 0.9915\n",
      "Epoch 181/400\n",
      "3s - loss: 0.0411 - fmeasure: 0.9843 - val_loss: 0.0236 - val_fmeasure: 0.9914\n",
      "Epoch 182/400\n",
      "3s - loss: 0.0412 - fmeasure: 0.9841 - val_loss: 0.0235 - val_fmeasure: 0.9915\n",
      "Epoch 183/400\n",
      "3s - loss: 0.0413 - fmeasure: 0.9841 - val_loss: 0.0236 - val_fmeasure: 0.9914\n",
      "Epoch 184/400\n",
      "3s - loss: 0.0408 - fmeasure: 0.9844 - val_loss: 0.0235 - val_fmeasure: 0.9915\n",
      "Epoch 185/400\n",
      "3s - loss: 0.0411 - fmeasure: 0.9843 - val_loss: 0.0235 - val_fmeasure: 0.9915\n",
      "Epoch 186/400\n",
      "2s - loss: 0.0407 - fmeasure: 0.9844 - val_loss: 0.0235 - val_fmeasure: 0.9915\n",
      "Epoch 187/400\n",
      "3s - loss: 0.0408 - fmeasure: 0.9844 - val_loss: 0.0234 - val_fmeasure: 0.9916\n",
      "Epoch 188/400\n",
      "3s - loss: 0.0410 - fmeasure: 0.9842 - val_loss: 0.0233 - val_fmeasure: 0.9915\n",
      "Epoch 189/400\n",
      "3s - loss: 0.0406 - fmeasure: 0.9843 - val_loss: 0.0233 - val_fmeasure: 0.9916\n",
      "Epoch 190/400\n",
      "3s - loss: 0.0412 - fmeasure: 0.9842 - val_loss: 0.0233 - val_fmeasure: 0.9916\n",
      "Epoch 191/400\n",
      "3s - loss: 0.0409 - fmeasure: 0.9844 - val_loss: 0.0233 - val_fmeasure: 0.9915\n",
      "Epoch 192/400\n",
      "3s - loss: 0.0404 - fmeasure: 0.9845 - val_loss: 0.0234 - val_fmeasure: 0.9916\n",
      "Epoch 193/400\n",
      "3s - loss: 0.0410 - fmeasure: 0.9843 - val_loss: 0.0232 - val_fmeasure: 0.9916\n",
      "Epoch 194/400\n",
      "3s - loss: 0.0408 - fmeasure: 0.9843 - val_loss: 0.0232 - val_fmeasure: 0.9916\n",
      "Epoch 195/400\n",
      "3s - loss: 0.0402 - fmeasure: 0.9848 - val_loss: 0.0233 - val_fmeasure: 0.9916\n",
      "Epoch 196/400\n",
      "3s - loss: 0.0416 - fmeasure: 0.9842 - val_loss: 0.0234 - val_fmeasure: 0.9916\n",
      "Epoch 197/400\n",
      "3s - loss: 0.0403 - fmeasure: 0.9848 - val_loss: 0.0231 - val_fmeasure: 0.9917\n",
      "Epoch 198/400\n",
      "3s - loss: 0.0403 - fmeasure: 0.9846 - val_loss: 0.0232 - val_fmeasure: 0.9916\n",
      "Epoch 199/400\n",
      "3s - loss: 0.0410 - fmeasure: 0.9843 - val_loss: 0.0232 - val_fmeasure: 0.9916\n",
      "Epoch 200/400\n",
      "3s - loss: 0.0405 - fmeasure: 0.9845 - val_loss: 0.0231 - val_fmeasure: 0.9917\n",
      "Epoch 201/400\n",
      "3s - loss: 0.0409 - fmeasure: 0.9845 - val_loss: 0.0231 - val_fmeasure: 0.9917\n",
      "Epoch 202/400\n",
      "3s - loss: 0.0411 - fmeasure: 0.9844 - val_loss: 0.0231 - val_fmeasure: 0.9917\n",
      "Epoch 203/400\n",
      "3s - loss: 0.0407 - fmeasure: 0.9844 - val_loss: 0.0230 - val_fmeasure: 0.9917\n",
      "Epoch 204/400\n",
      "3s - loss: 0.0407 - fmeasure: 0.9844 - val_loss: 0.0230 - val_fmeasure: 0.9917\n",
      "Epoch 205/400\n",
      "3s - loss: 0.0403 - fmeasure: 0.9846 - val_loss: 0.0230 - val_fmeasure: 0.9917\n",
      "Epoch 206/400\n",
      "3s - loss: 0.0403 - fmeasure: 0.9848 - val_loss: 0.0230 - val_fmeasure: 0.9917\n",
      "Epoch 207/400\n",
      "3s - loss: 0.0406 - fmeasure: 0.9847 - val_loss: 0.0230 - val_fmeasure: 0.9918\n",
      "Epoch 208/400\n",
      "3s - loss: 0.0405 - fmeasure: 0.9844 - val_loss: 0.0230 - val_fmeasure: 0.9918\n",
      "Epoch 209/400\n",
      "3s - loss: 0.0410 - fmeasure: 0.9844 - val_loss: 0.0230 - val_fmeasure: 0.9918\n",
      "Epoch 210/400\n",
      "3s - loss: 0.0404 - fmeasure: 0.9845 - val_loss: 0.0230 - val_fmeasure: 0.9918\n",
      "Epoch 211/400\n",
      "3s - loss: 0.0408 - fmeasure: 0.9847 - val_loss: 0.0229 - val_fmeasure: 0.9919\n",
      "Epoch 212/400\n",
      "3s - loss: 0.0405 - fmeasure: 0.9845 - val_loss: 0.0229 - val_fmeasure: 0.9919\n",
      "Epoch 213/400\n",
      "3s - loss: 0.0403 - fmeasure: 0.9845 - val_loss: 0.0229 - val_fmeasure: 0.9919\n",
      "Epoch 214/400\n",
      "3s - loss: 0.0398 - fmeasure: 0.9848 - val_loss: 0.0228 - val_fmeasure: 0.9919\n",
      "Epoch 215/400\n",
      "3s - loss: 0.0403 - fmeasure: 0.9848 - val_loss: 0.0229 - val_fmeasure: 0.9919\n",
      "Epoch 216/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9847 - val_loss: 0.0229 - val_fmeasure: 0.9919\n",
      "Epoch 217/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9847 - val_loss: 0.0228 - val_fmeasure: 0.9919\n",
      "Epoch 218/400\n",
      "3s - loss: 0.0396 - fmeasure: 0.9847 - val_loss: 0.0228 - val_fmeasure: 0.9919\n",
      "Epoch 219/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9848 - val_loss: 0.0228 - val_fmeasure: 0.9919\n",
      "Epoch 220/400\n",
      "3s - loss: 0.0405 - fmeasure: 0.9845 - val_loss: 0.0229 - val_fmeasure: 0.9919\n",
      "Epoch 221/400\n",
      "3s - loss: 0.0404 - fmeasure: 0.9844 - val_loss: 0.0229 - val_fmeasure: 0.9919\n",
      "Epoch 222/400\n",
      "3s - loss: 0.0399 - fmeasure: 0.9847 - val_loss: 0.0228 - val_fmeasure: 0.9919\n",
      "Epoch 223/400\n",
      "3s - loss: 0.0396 - fmeasure: 0.9848 - val_loss: 0.0227 - val_fmeasure: 0.9920\n",
      "Epoch 224/400\n",
      "3s - loss: 0.0403 - fmeasure: 0.9846 - val_loss: 0.0228 - val_fmeasure: 0.9920\n",
      "Epoch 225/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9848 - val_loss: 0.0228 - val_fmeasure: 0.9920\n",
      "Epoch 226/400\n",
      "3s - loss: 0.0396 - fmeasure: 0.9849 - val_loss: 0.0226 - val_fmeasure: 0.9921\n",
      "Epoch 227/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9848 - val_loss: 0.0228 - val_fmeasure: 0.9920\n",
      "Epoch 228/400\n",
      "3s - loss: 0.0401 - fmeasure: 0.9846 - val_loss: 0.0227 - val_fmeasure: 0.9921\n",
      "Epoch 229/400\n",
      "3s - loss: 0.0398 - fmeasure: 0.9849 - val_loss: 0.0226 - val_fmeasure: 0.9921\n",
      "Epoch 230/400\n",
      "3s - loss: 0.0405 - fmeasure: 0.9845 - val_loss: 0.0227 - val_fmeasure: 0.9921\n",
      "Epoch 231/400\n",
      "3s - loss: 0.0399 - fmeasure: 0.9848 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 232/400\n",
      "3s - loss: 0.0392 - fmeasure: 0.9852 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 233/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9847 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 234/400\n",
      "3s - loss: 0.0397 - fmeasure: 0.9849 - val_loss: 0.0225 - val_fmeasure: 0.9922\n",
      "Epoch 235/400\n",
      "3s - loss: 0.0391 - fmeasure: 0.9853 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 236/400\n",
      "3s - loss: 0.0398 - fmeasure: 0.9846 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 237/400\n",
      "3s - loss: 0.0401 - fmeasure: 0.9846 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 238/400\n",
      "3s - loss: 0.0402 - fmeasure: 0.9850 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 239/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9847 - val_loss: 0.0225 - val_fmeasure: 0.9921\n",
      "Epoch 240/400\n",
      "3s - loss: 0.0400 - fmeasure: 0.9849 - val_loss: 0.0224 - val_fmeasure: 0.9922\n",
      "Epoch 241/400\n",
      "3s - loss: 0.0399 - fmeasure: 0.9848 - val_loss: 0.0224 - val_fmeasure: 0.9921\n",
      "Epoch 242/400\n",
      "3s - loss: 0.0402 - fmeasure: 0.9846 - val_loss: 0.0224 - val_fmeasure: 0.9922\n",
      "Epoch 243/400\n",
      "3s - loss: 0.0395 - fmeasure: 0.9851 - val_loss: 0.0224 - val_fmeasure: 0.9922\n",
      "Epoch 244/400\n",
      "3s - loss: 0.0391 - fmeasure: 0.9854 - val_loss: 0.0224 - val_fmeasure: 0.9922\n",
      "Epoch 245/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9852 - val_loss: 0.0224 - val_fmeasure: 0.9922\n",
      "Epoch 246/400\n",
      "3s - loss: 0.0392 - fmeasure: 0.9851 - val_loss: 0.0223 - val_fmeasure: 0.9922\n",
      "Epoch 247/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9850 - val_loss: 0.0223 - val_fmeasure: 0.9922\n",
      "Epoch 248/400\n",
      "3s - loss: 0.0392 - fmeasure: 0.9851 - val_loss: 0.0224 - val_fmeasure: 0.9922\n",
      "Epoch 249/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9849 - val_loss: 0.0223 - val_fmeasure: 0.9923\n",
      "Epoch 250/400\n",
      "3s - loss: 0.0401 - fmeasure: 0.9846 - val_loss: 0.0224 - val_fmeasure: 0.9922\n",
      "Epoch 251/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9850 - val_loss: 0.0223 - val_fmeasure: 0.9923\n",
      "Epoch 252/400\n",
      "3s - loss: 0.0395 - fmeasure: 0.9851 - val_loss: 0.0223 - val_fmeasure: 0.9922\n",
      "Epoch 253/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9853 - val_loss: 0.0223 - val_fmeasure: 0.9922\n",
      "Epoch 254/400\n",
      "3s - loss: 0.0404 - fmeasure: 0.9846 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 255/400\n",
      "3s - loss: 0.0392 - fmeasure: 0.9852 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 256/400\n",
      "3s - loss: 0.0395 - fmeasure: 0.9851 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 257/400\n",
      "3s - loss: 0.0396 - fmeasure: 0.9850 - val_loss: 0.0223 - val_fmeasure: 0.9922\n",
      "Epoch 258/400\n",
      "3s - loss: 0.0395 - fmeasure: 0.9849 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 259/400\n",
      "3s - loss: 0.0394 - fmeasure: 0.9849 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 260/400\n",
      "3s - loss: 0.0394 - fmeasure: 0.9849 - val_loss: 0.0222 - val_fmeasure: 0.9922\n",
      "Epoch 261/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9850 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 262/400\n",
      "3s - loss: 0.0389 - fmeasure: 0.9853 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 263/400\n",
      "3s - loss: 0.0398 - fmeasure: 0.9850 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 264/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9851 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 265/400\n",
      "4s - loss: 0.0389 - fmeasure: 0.9853 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 266/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9851 - val_loss: 0.0222 - val_fmeasure: 0.9923\n",
      "Epoch 267/400\n",
      "3s - loss: 0.0397 - fmeasure: 0.9850 - val_loss: 0.0221 - val_fmeasure: 0.9923\n",
      "Epoch 268/400\n",
      "3s - loss: 0.0388 - fmeasure: 0.9855 - val_loss: 0.0221 - val_fmeasure: 0.9923\n",
      "Epoch 269/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9853 - val_loss: 0.0220 - val_fmeasure: 0.9923\n",
      "Epoch 270/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9849 - val_loss: 0.0221 - val_fmeasure: 0.9922\n",
      "Epoch 271/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9850 - val_loss: 0.0221 - val_fmeasure: 0.9922\n",
      "Epoch 272/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9851 - val_loss: 0.0222 - val_fmeasure: 0.9922\n",
      "Epoch 273/400\n",
      "3s - loss: 0.0396 - fmeasure: 0.9849 - val_loss: 0.0221 - val_fmeasure: 0.9922\n",
      "Epoch 274/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9856 - val_loss: 0.0221 - val_fmeasure: 0.9923\n",
      "Epoch 275/400\n",
      "3s - loss: 0.0388 - fmeasure: 0.9854 - val_loss: 0.0220 - val_fmeasure: 0.9923\n",
      "Epoch 276/400\n",
      "3s - loss: 0.0395 - fmeasure: 0.9851 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 277/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9850 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 278/400\n",
      "3s - loss: 0.0392 - fmeasure: 0.9851 - val_loss: 0.0220 - val_fmeasure: 0.9923\n",
      "Epoch 279/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9853 - val_loss: 0.0220 - val_fmeasure: 0.9923\n",
      "Epoch 280/400\n",
      "3s - loss: 0.0392 - fmeasure: 0.9853 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 281/400\n",
      "3s - loss: 0.0389 - fmeasure: 0.9852 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 282/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9852 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 283/400\n",
      "4s - loss: 0.0391 - fmeasure: 0.9851 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 284/400\n",
      "3s - loss: 0.0389 - fmeasure: 0.9850 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 285/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9854 - val_loss: 0.0218 - val_fmeasure: 0.9923\n",
      "Epoch 286/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9853 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 287/400\n",
      "3s - loss: 0.0388 - fmeasure: 0.9855 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 288/400\n",
      "3s - loss: 0.0386 - fmeasure: 0.9854 - val_loss: 0.0218 - val_fmeasure: 0.9923\n",
      "Epoch 289/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9852 - val_loss: 0.0218 - val_fmeasure: 0.9923\n",
      "Epoch 290/400\n",
      "3s - loss: 0.0391 - fmeasure: 0.9851 - val_loss: 0.0219 - val_fmeasure: 0.9923\n",
      "Epoch 291/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9854 - val_loss: 0.0218 - val_fmeasure: 0.9923\n",
      "Epoch 292/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9853 - val_loss: 0.0219 - val_fmeasure: 0.9924\n",
      "Epoch 293/400\n",
      "3s - loss: 0.0393 - fmeasure: 0.9851 - val_loss: 0.0218 - val_fmeasure: 0.9923\n",
      "Epoch 294/400\n",
      "3s - loss: 0.0396 - fmeasure: 0.9850 - val_loss: 0.0218 - val_fmeasure: 0.9923\n",
      "Epoch 295/400\n",
      "3s - loss: 0.0385 - fmeasure: 0.9855 - val_loss: 0.0218 - val_fmeasure: 0.9923\n",
      "Epoch 296/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9853 - val_loss: 0.0217 - val_fmeasure: 0.9924\n",
      "Epoch 297/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9851 - val_loss: 0.0219 - val_fmeasure: 0.9924\n",
      "Epoch 298/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9857 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 299/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9855 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 300/400\n",
      "3s - loss: 0.0390 - fmeasure: 0.9852 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 301/400\n",
      "3s - loss: 0.0386 - fmeasure: 0.9854 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 302/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9857 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 303/400\n",
      "3s - loss: 0.0386 - fmeasure: 0.9853 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 304/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9852 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 305/400\n",
      "3s - loss: 0.0391 - fmeasure: 0.9852 - val_loss: 0.0218 - val_fmeasure: 0.9924\n",
      "Epoch 306/400\n",
      "3s - loss: 0.0388 - fmeasure: 0.9855 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 307/400\n",
      "3s - loss: 0.0386 - fmeasure: 0.9855 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 308/400\n",
      "3s - loss: 0.0386 - fmeasure: 0.9855 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 309/400\n",
      "3s - loss: 0.0384 - fmeasure: 0.9854 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 310/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9856 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 311/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9853 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 312/400\n",
      "3s - loss: 0.0389 - fmeasure: 0.9852 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 313/400\n",
      "3s - loss: 0.0385 - fmeasure: 0.9854 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 314/400\n",
      "3s - loss: 0.0381 - fmeasure: 0.9854 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 315/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9855 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 316/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9856 - val_loss: 0.0215 - val_fmeasure: 0.9925\n",
      "Epoch 317/400\n",
      "3s - loss: 0.0385 - fmeasure: 0.9857 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 318/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9854 - val_loss: 0.0215 - val_fmeasure: 0.9925\n",
      "Epoch 319/400\n",
      "3s - loss: 0.0381 - fmeasure: 0.9857 - val_loss: 0.0215 - val_fmeasure: 0.9925\n",
      "Epoch 320/400\n",
      "3s - loss: 0.0387 - fmeasure: 0.9852 - val_loss: 0.0216 - val_fmeasure: 0.9925\n",
      "Epoch 321/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9856 - val_loss: 0.0215 - val_fmeasure: 0.9925\n",
      "Epoch 322/400\n",
      "3s - loss: 0.0384 - fmeasure: 0.9854 - val_loss: 0.0215 - val_fmeasure: 0.9926\n",
      "Epoch 323/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9855 - val_loss: 0.0215 - val_fmeasure: 0.9926\n",
      "Epoch 324/400\n",
      "3s - loss: 0.0386 - fmeasure: 0.9853 - val_loss: 0.0215 - val_fmeasure: 0.9925\n",
      "Epoch 325/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9858 - val_loss: 0.0214 - val_fmeasure: 0.9926\n",
      "Epoch 326/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9856 - val_loss: 0.0214 - val_fmeasure: 0.9926\n",
      "Epoch 327/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9859 - val_loss: 0.0215 - val_fmeasure: 0.9926\n",
      "Epoch 328/400\n",
      "3s - loss: 0.0384 - fmeasure: 0.9853 - val_loss: 0.0215 - val_fmeasure: 0.9925\n",
      "Epoch 329/400\n",
      "3s - loss: 0.0388 - fmeasure: 0.9854 - val_loss: 0.0215 - val_fmeasure: 0.9925\n",
      "Epoch 330/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9855 - val_loss: 0.0214 - val_fmeasure: 0.9926\n",
      "Epoch 331/400\n",
      "3s - loss: 0.0386 - fmeasure: 0.9854 - val_loss: 0.0214 - val_fmeasure: 0.9926\n",
      "Epoch 332/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9857 - val_loss: 0.0214 - val_fmeasure: 0.9926\n",
      "Epoch 333/400\n",
      "3s - loss: 0.0384 - fmeasure: 0.9854 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 334/400\n",
      "3s - loss: 0.0381 - fmeasure: 0.9856 - val_loss: 0.0214 - val_fmeasure: 0.9926\n",
      "Epoch 335/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9856 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 336/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9858 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 337/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9856 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 338/400\n",
      "3s - loss: 0.0385 - fmeasure: 0.9854 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 339/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 340/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9854 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 341/400\n",
      "3s - loss: 0.0381 - fmeasure: 0.9854 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 342/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9855 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 343/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9859 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 344/400\n",
      "3s - loss: 0.0377 - fmeasure: 0.9857 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 345/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9857 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 346/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9859 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 347/400\n",
      "3s - loss: 0.0381 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 348/400\n",
      "3s - loss: 0.0388 - fmeasure: 0.9854 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 349/400\n",
      "3s - loss: 0.0377 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 350/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 351/400\n",
      "3s - loss: 0.0377 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 352/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9856 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 353/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 354/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 355/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9857 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 356/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9857 - val_loss: 0.0211 - val_fmeasure: 0.9926\n",
      "Epoch 357/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9854 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 358/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9856 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 359/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9857 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 360/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9858 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 361/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9857 - val_loss: 0.0213 - val_fmeasure: 0.9926\n",
      "Epoch 362/400\n",
      "3s - loss: 0.0383 - fmeasure: 0.9855 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 363/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9859 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 364/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9860 - val_loss: 0.0211 - val_fmeasure: 0.9926\n",
      "Epoch 365/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9860 - val_loss: 0.0211 - val_fmeasure: 0.9926\n",
      "Epoch 366/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9857 - val_loss: 0.0212 - val_fmeasure: 0.9926\n",
      "Epoch 367/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9859 - val_loss: 0.0211 - val_fmeasure: 0.9927\n",
      "Epoch 368/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9861 - val_loss: 0.0211 - val_fmeasure: 0.9927\n",
      "Epoch 369/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9856 - val_loss: 0.0211 - val_fmeasure: 0.9927\n",
      "Epoch 370/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9857 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 371/400\n",
      "3s - loss: 0.0377 - fmeasure: 0.9859 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 372/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9859 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 373/400\n",
      "3s - loss: 0.0377 - fmeasure: 0.9858 - val_loss: 0.0210 - val_fmeasure: 0.9926\n",
      "Epoch 374/400\n",
      "3s - loss: 0.0381 - fmeasure: 0.9857 - val_loss: 0.0210 - val_fmeasure: 0.9926\n",
      "Epoch 375/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9860 - val_loss: 0.0210 - val_fmeasure: 0.9926\n",
      "Epoch 376/400\n",
      "3s - loss: 0.0375 - fmeasure: 0.9858 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 377/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9857 - val_loss: 0.0210 - val_fmeasure: 0.9926\n",
      "Epoch 378/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9857 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 379/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9860 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 380/400\n",
      "3s - loss: 0.0382 - fmeasure: 0.9855 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 381/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9857 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 382/400\n",
      "3s - loss: 0.0379 - fmeasure: 0.9856 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 383/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9861 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 384/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9857 - val_loss: 0.0209 - val_fmeasure: 0.9926\n",
      "Epoch 385/400\n",
      "3s - loss: 0.0372 - fmeasure: 0.9861 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 386/400\n",
      "3s - loss: 0.0373 - fmeasure: 0.9859 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 387/400\n",
      "3s - loss: 0.0369 - fmeasure: 0.9863 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 388/400\n",
      "3s - loss: 0.0378 - fmeasure: 0.9857 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 389/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9861 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 390/400\n",
      "3s - loss: 0.0376 - fmeasure: 0.9861 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 391/400\n",
      "3s - loss: 0.0375 - fmeasure: 0.9859 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 392/400\n",
      "3s - loss: 0.0372 - fmeasure: 0.9859 - val_loss: 0.0210 - val_fmeasure: 0.9927\n",
      "Epoch 393/400\n",
      "3s - loss: 0.0377 - fmeasure: 0.9860 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 394/400\n",
      "3s - loss: 0.0372 - fmeasure: 0.9862 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 395/400\n",
      "3s - loss: 0.0374 - fmeasure: 0.9859 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 396/400\n",
      "3s - loss: 0.0380 - fmeasure: 0.9858 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 397/400\n",
      "3s - loss: 0.0377 - fmeasure: 0.9856 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 398/400\n",
      "3s - loss: 0.0373 - fmeasure: 0.9861 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 399/400\n",
      "3s - loss: 0.0373 - fmeasure: 0.9861 - val_loss: 0.0209 - val_fmeasure: 0.9927\n",
      "Epoch 400/400\n",
      "3s - loss: 0.0373 - fmeasure: 0.9860 - val_loss: 0.0209 - val_fmeasure: 0.9927\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, nb_epoch = 400, batch_size = 2000, verbose = 2, validation_split = .20,\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Neural Network achieves an f1 score of  0.992929874218 on the testing data\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions[:] = predictions[:]>0.5\n",
    "\n",
    "print \"Our Neural Network achieves an f1 score of \" , f1_score(y_test, zeme, pos_label = 0) , \"on the testing data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
